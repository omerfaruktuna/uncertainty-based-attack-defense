{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIFAR_VGG19bn_test_attack_performances.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6d4085118aa42c3816e06a0b6100d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_632e06a3103b465e8d50c8bf68ff4da1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b373cce1fb742939e90d4b0d59db652",
              "IPY_MODEL_c2a09a316ed94312a372427558df38ca",
              "IPY_MODEL_7c1b6d7522b142c080082b3908c32ce8"
            ]
          }
        },
        "632e06a3103b465e8d50c8bf68ff4da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b373cce1fb742939e90d4b0d59db652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_573204a3cb5d4f0d8f12414278309a80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa02cb0385a14fe1b646c7be16184252"
          }
        },
        "c2a09a316ed94312a372427558df38ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80682f07da7444449e824342ac91dc59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53c9884276a64b3f85366c29d68382a2"
          }
        },
        "7c1b6d7522b142c080082b3908c32ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd0a8a355ed140659069b720d74c8211",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 55619314.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8072c71c65c4d6bb8c08e71c42d8d9d"
          }
        },
        "573204a3cb5d4f0d8f12414278309a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa02cb0385a14fe1b646c7be16184252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80682f07da7444449e824342ac91dc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53c9884276a64b3f85366c29d68382a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd0a8a355ed140659069b720d74c8211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8072c71c65c4d6bb8c08e71c42d8d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCz39y-m3zmO",
        "outputId": "29362e69-31aa-4e08-9c29-0be5cf307626"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeEeTeBvM4EW",
        "outputId": "aae7746a-e804-41ab-8e48-7d46f1e0832c"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 733 kB/s \n",
            "\u001b[?25hCollecting GitPython>=3.0.7\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Collecting eagerpy==0.29.0\n",
            "  Downloading eagerpy-0.29.0-py3-none-any.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.4)\n",
            "Installing collected packages: smmap, gitdb, requests, GitPython, eagerpy, foolbox\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.18 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.26.0 smmap-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqsac7FMSyD"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models\n",
        "import urllib\n",
        "import os\n",
        "import math\n",
        "import torch.nn.init as init\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSybUHgrrOS5"
      },
      "source": [
        "__all__ = [\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1zyLjRErTMM"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    '''\n",
        "    VGG model \n",
        "    '''\n",
        "    def __init__(self, features):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "         # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-LvQxl8rT75"
      },
      "source": [
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGLxfIZ2rZNI"
      },
      "source": [
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
        "          512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBnNTXMWrcei"
      },
      "source": [
        "def vgg19_bn():\n",
        "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['E'], batch_norm=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhzwADg7uL_Y"
      },
      "source": [
        "\n",
        "transform = transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQDTa3PxKlK"
      },
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.Tensor(mean)\n",
        "        self.std = torch.Tensor(std)\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]\n",
        "\n",
        "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "mc_dropout_samples = 30\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2pOiQCkri3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d6d4085118aa42c3816e06a0b6100d86",
            "632e06a3103b465e8d50c8bf68ff4da1",
            "9b373cce1fb742939e90d4b0d59db652",
            "c2a09a316ed94312a372427558df38ca",
            "7c1b6d7522b142c080082b3908c32ce8",
            "573204a3cb5d4f0d8f12414278309a80",
            "fa02cb0385a14fe1b646c7be16184252",
            "80682f07da7444449e824342ac91dc59",
            "53c9884276a64b3f85366c29d68382a2",
            "dd0a8a355ed140659069b720d74c8211",
            "f8072c71c65c4d6bb8c08e71c42d8d9d"
          ]
        },
        "outputId": "19188b05-4470-4d3d-b511-f78c45854da6"
      },
      "source": [
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='data', train=False, transform=transform, download=True),\n",
        "        batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d4085118aa42c3816e06a0b6100d86",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AUGDSU4M0Cq"
      },
      "source": [
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSQY-4NWIZiz"
      },
      "source": [
        "def fgsm(image,model,epsilon, label):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "    o = model(norm((image + delta)))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "    \n",
        "    loss.backward(torch.ones_like(loss))\n",
        "\n",
        "    delta.data = delta + epsilon * delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hQhdlSjaPtN"
      },
      "source": [
        "\n",
        "def rectified_fgsm(image,model,epsilon):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(norm(image))\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    dropout_predictions = torch.zeros([mc_dropout_samples,item_count,10])\n",
        "\n",
        "    for i in range(mc_dropout_samples):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        output = model(norm((image + delta)))\n",
        "        output = softmax(output)\n",
        "\n",
        "        dropout_predictions[i] = output\n",
        "\n",
        "    variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "    var = variance.mean(1,True)\n",
        "    var = var.reshape(1,item_count)\n",
        "    var = var.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    o = model(norm((image + delta)))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "\n",
        "    loss.backward(torch.ones_like(var))\n",
        "    delta_loss = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    var.backward(torch.ones_like(var))\n",
        "    delta_unc = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    zeros = torch.zeros_like(delta_loss)\n",
        "    delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "    delta.data = (delta + epsilon * delta_unc)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6B7XuEsIeBL"
      },
      "source": [
        "def bim(image,model,epsilon, label, alpha, num_iter):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        model.eval()\n",
        "        o = model(norm((image + delta)))\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "\n",
        "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "        delta.grad.zero_()\n",
        "\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTOINsW7Htkr"
      },
      "source": [
        "\n",
        "def rectified_bim(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(norm(image))\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([mc_dropout_samples,item_count,10])\n",
        "\n",
        "        for i in range(mc_dropout_samples):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model(norm((image + delta)))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model(norm((image + delta)))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model(norm((image + delta)))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp, retain_graph=True)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp, retain_graph=True)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_match] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLF08QGajdeL"
      },
      "source": [
        "def pgd(image,model,epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for i in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            model.eval()\n",
        "            o = model(norm((image + delta)))\n",
        "\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            loss.backward(torch.ones_like(loss))\n",
        "\n",
        "            delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "            delta.grad.zero_()\n",
        "        \n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model(norm((image + delta))),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcvg7Ss_aa12"
      },
      "source": [
        "\n",
        "def rectified_pgd(image, model, epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for r in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            o = model(norm(image))\n",
        "            o = softmax(o)\n",
        "        init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "        enable_dropout(model)\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            dropout_predictions = torch.zeros([mc_dropout_samples,item_count,10])\n",
        "\n",
        "            for i in range(mc_dropout_samples):\n",
        "\n",
        "                enable_dropout(model)\n",
        "                output = model(norm((image + delta)))\n",
        "                output = softmax(output)\n",
        "\n",
        "                dropout_predictions[i] = output\n",
        "\n",
        "            variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "            var = variance.mean(1,True)\n",
        "            var = var.reshape(1,item_count)\n",
        "            var = var.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            o = model(norm((image + delta)))\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            if t == 0:\n",
        "\n",
        "                loss.backward(torch.ones_like(var))\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                var.backward(torch.ones_like(var))\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "                delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            else:\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    o = model(norm((image + delta)))\n",
        "                    o = softmax(o)\n",
        "                inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_notmatch] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp, retain_graph=True)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp, retain_graph=True)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_match] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model(norm((image + delta))),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFcxfzsikYWL"
      },
      "source": [
        "def norms(Z):\n",
        "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
        "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCTWpJeMhmH"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 3./255\n",
        "alpha = 0.4 * eps\n",
        "num_iter = 5\n",
        "\n",
        "num_restart = 5\n",
        "\n",
        "count_correct_after_attack = 0\n",
        "count_wrong_after_attack = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwKm-A1gM1ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75485da-9fda-4bc8-ee2b-b2f3a9db4f02"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model_cnn = vgg19_bn()\n",
        "model_cnn.load_state_dict(torch.load(\"/content/gdrive/MyDrive/model_cnn_vgg19bn_cifar10.pt\"))\n",
        "model_cnn.eval()\n",
        "model_cnn.to(device)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-13 13:09:28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6C5yBDM5AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3f2581-d134-4ea4-cac7-e17a8369ae13"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(norm(image))\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    if inds_correct.shape[0] == 0:\n",
        "        continue\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    #pert = fgsm(image,model_cnn,eps, label)\n",
        "    #pert = rectified_fgsm(image, model_cnn, eps)\n",
        "    #pert = bim(image, model_cnn, eps, label, alpha, num_iter)\n",
        "    #pert = rectified_bim(image, model_cnn, eps, num_iter, alpha)\n",
        "    #pert = pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)\n",
        "    pert = rectified_pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)   \n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(norm(pert))\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "    inds_correct_after_attack = inds_correct_after_attack.tolist()\n",
        "    inds_wrong_after_attack = inds_wrong_after_attack.tolist()\n",
        "\n",
        "    count_correct_after_attack += len(inds_correct_after_attack)\n",
        "    count_wrong_after_attack += len(inds_wrong_after_attack)\n",
        "\n",
        "\n",
        "    if i%30 == 0:\n",
        "      print(\"Success ratio for the attack is : %{:.2f}\".format(100 * count_wrong_after_attack / (count_correct_after_attack + count_wrong_after_attack)))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success ratio for the attack is : %78.85\n",
            "Success ratio for the attack is : %83.01\n",
            "Success ratio for the attack is : %83.00\n",
            "Success ratio for the attack is : %83.38\n",
            "Success ratio for the attack is : %83.97\n",
            "Success ratio for the attack is : %83.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-KlO9zTNWN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c701796d-c37b-4c50-face-37f8da206349"
      },
      "source": [
        "print(\"count_wrong_after_attack \", count_wrong_after_attack)\n",
        "print(\"count_correct_after_attack \", count_correct_after_attack)\n",
        "\n",
        "print(\"Success ratio for the attack is : %{:.2f}\".format(\n",
        "    100 * count_wrong_after_attack / (count_correct_after_attack + count_wrong_after_attack)))\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count_wrong_after_attack  7204\n",
            "count_correct_after_attack  1375\n",
            "Success ratio for the attack is : %83.97\n",
            "2021-09-13 17:44:12\n"
          ]
        }
      ]
    }
  ]
}