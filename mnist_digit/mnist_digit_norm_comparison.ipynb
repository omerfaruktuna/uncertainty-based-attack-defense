{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_digit_norm_comparison.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BNvAVpBTXOy"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "from numpy.linalg import norm\n",
        "import torchvision.models as models\n",
        "import warnings\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngvf3kK8Twqt"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*32, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.2)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = self.drop_layer(F.relu(self.conv3(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 7*7*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pWfoJxTbGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d199ea-f914-465e-e557-b363423f0883"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = CNN()\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn_mnist_digit.pt\", map_location=device))\n",
        "model_cnn = model_cnn.to(device)\n",
        "model_cnn.eval()\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-07 11:03:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KNUImwjTfF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6166908e-ce27-412b-c925-9228f914f582"
      },
      "source": [
        "\n",
        "batch_size = 256\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mev7JlzTh2j"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "eps = 0.16\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "\n",
        "num_restart = 5\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbzluyWmTjz8"
      },
      "source": [
        "def fgsm(image,model,epsilon, label):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "    o = model((image + delta))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "    \n",
        "    loss.backward(torch.ones_like(loss))\n",
        "\n",
        "    delta.data = delta + epsilon * delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hx9nAX-kgFs"
      },
      "source": [
        "\n",
        "def rectified_fgsm(image,model,epsilon):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "    for i in range(50):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        output = model((image + delta))\n",
        "        output = softmax(output)\n",
        "\n",
        "        dropout_predictions[i] = output\n",
        "\n",
        "    variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "    var = variance.mean(1,True)\n",
        "    var = var.reshape(1,item_count)\n",
        "    var = var.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    o = model((image + delta))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "\n",
        "    loss.backward(torch.ones_like(var))\n",
        "    delta_loss = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    var.backward(torch.ones_like(var))\n",
        "    delta_unc = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    zeros = torch.zeros_like(delta_loss)\n",
        "    delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "    delta.data = (delta + epsilon * delta_unc)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBv4HpMUTl9i"
      },
      "source": [
        "def bim(image,model,epsilon, label, alpha, num_iter):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta))\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "\n",
        "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "        delta.grad.zero_()\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp4lK_24Tn_2"
      },
      "source": [
        "\n",
        "def rectified_bim(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image + delta))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp, retain_graph=True)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp, retain_graph=True)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_match] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp2KiKzAmiFL"
      },
      "source": [
        "def pgd(image,model,epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for i in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            model.eval()\n",
        "            o = model((image + delta))\n",
        "\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            loss.backward(torch.ones_like(loss))\n",
        "\n",
        "            delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "            delta.grad.zero_()\n",
        "        \n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model((image + delta)),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejNX1gqa1tnD"
      },
      "source": [
        "\n",
        "def rectified_pgd(image, model, epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    for r in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            dropout_predictions = torch.zeros([50,item_count,10])\n",
        "            enable_dropout(model)\n",
        "\n",
        "            for i in range(50):\n",
        "               \n",
        "                output = model((image + delta))\n",
        "                output = softmax(output)\n",
        "\n",
        "                dropout_predictions[i] = output\n",
        "\n",
        "            variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "            var = variance.mean(1,True)\n",
        "            var = var.reshape(1,item_count)\n",
        "            var = var.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            o = model((image + delta))\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            if t == 0:\n",
        "\n",
        "                loss.backward(torch.ones_like(var))\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                var.backward(torch.ones_like(var))\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "                delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            else:\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    o = model((image + delta))\n",
        "                    o = softmax(o)\n",
        "                inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_notmatch] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp, retain_graph=True)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp, retain_graph=True)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_match] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model((image + delta)),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEEHLsLh2wIS"
      },
      "source": [
        "sum_l2 = 0\n",
        "sum_l1 = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXVE8LMATpsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b23fc9-a183-44eb-c2d0-2515389a859e"
      },
      "source": [
        "\n",
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(image)\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "    #pert = fgsm(image, model_cnn, eps, label)\n",
        "    \n",
        "    pert = rectified_fgsm(image, model_cnn, eps)\n",
        "\n",
        "    #pert = bim(image, model_cnn, eps, label, alpha, num_iter)\n",
        "\n",
        "    #pert = rectified_bim(image, model_cnn, eps, num_iter, alpha)\n",
        "\n",
        "    #pert = pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)\n",
        "    \n",
        "    #pert = rectified_pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)\n",
        "    \n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "    inds_correct_after_attackk = inds_correct_after_attack.tolist()\n",
        "    inds_wrong_after_attackk = inds_wrong_after_attack.tolist()\n",
        "\n",
        "    count_unsuccessfull_attack += len(inds_correct_after_attackk)\n",
        "    count_successfull_attack += len(inds_wrong_after_attackk)\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "\n",
        "    if i%30==0:\n",
        "      print(\"Success ratio for the attack is : %{:.2f}\".format(\n",
        "    100 * count_successfull_attack / (count_successfull_attack + count_unsuccessfull_attack)))\n",
        "      \n",
        "    if i == 0:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success ratio for the attack is : %42.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihHWh3ZA2HWw",
        "outputId": "5a02c485-51bd-4c44-d02e-0e67a4cfc97a"
      },
      "source": [
        "number = image.shape[0]\n",
        "print(\"number \", number)\n",
        "\n",
        "for n in range(number):\n",
        "  perturbation = pert[n] - image[n]\n",
        "  perturbation = perturbation.cpu()\n",
        "\n",
        "  sum_l2 = sum_l2 + norm(perturbation.flatten(), 2)\n",
        "  sum_l1 = sum_l1 + norm(perturbation.flatten(), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number  107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhcwvfyD3dhP",
        "outputId": "459f8fad-b363-4d43-d63a-8ed10e354ad6"
      },
      "source": [
        "print(' Mean of L2 norm of perturbation: {}'.format(sum_l2/number, 2))\n",
        "print(' Mean of L1 norm of perturbation: {}'.format(sum_l1/number, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean of L2 norm of perturbation: 3.0691128490127135\n",
            " Mean of L1 norm of perturbation: 59.53189254475531\n"
          ]
        }
      ]
    }
  ]
}