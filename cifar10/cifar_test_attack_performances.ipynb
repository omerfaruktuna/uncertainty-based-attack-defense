{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_test_attack_performances.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UZiEydmTRpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c740b9d0-9ec2-451c-c5f1-046a7844748a"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (2.26.0)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.1.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: eagerpy==0.29.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (0.29.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (4.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAjugze8TT3Y"
      },
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfDeepFoolAttack"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BNvAVpBTXOy"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "from numpy.linalg import norm\n",
        "import torchvision.models as models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngvf3kK8Twqt"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(4096, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "\n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "\n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pWfoJxTbGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54346803-b064-482d-9301-15b99957f132"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = CNN()\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn_cifar10.pt\", map_location=device))\n",
        "model_cnn = model_cnn.to(device)\n",
        "model_cnn.eval()\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-06 19:44:40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KNUImwjTfF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089d3710-9de0-463d-8143-862db9ab9133"
      },
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.Tensor(mean)\n",
        "        self.std = torch.Tensor(std)\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]\n",
        "\n",
        "batch_size = 64\n",
        "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "test_data = datasets.CIFAR10(root='/CIFARDATA', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mev7JlzTh2j"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "eps = 2./255\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "\n",
        "num_restart = 5\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbzluyWmTjz8"
      },
      "source": [
        "def fgsm(image,model,epsilon, label):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "    o = model(norm((image + delta)))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "    \n",
        "    loss.backward(torch.ones_like(loss))\n",
        "\n",
        "    delta.data = delta + epsilon * delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hx9nAX-kgFs"
      },
      "source": [
        "\n",
        "def rectified_fgsm(image,model,epsilon):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(norm(image))\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "    for i in range(50):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        output = model(norm((image + delta)))\n",
        "        output = softmax(output)\n",
        "\n",
        "        dropout_predictions[i] = output\n",
        "\n",
        "    variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "    var = variance.mean(1,True)\n",
        "    var = var.reshape(1,item_count)\n",
        "    var = var.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    o = model(norm((image + delta)))\n",
        "    loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "    loss = loss.reshape(1, item_count)\n",
        "\n",
        "    loss.backward(torch.ones_like(var))\n",
        "    delta_loss = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    var.backward(torch.ones_like(var))\n",
        "    delta_unc = delta.grad.detach().sign()\n",
        "    delta.grad.zero_()\n",
        "    delta.grad = None\n",
        "\n",
        "    zeros = torch.zeros_like(delta_loss)\n",
        "    delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "    delta.data = (delta + epsilon * delta_unc)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBv4HpMUTl9i"
      },
      "source": [
        "def bim(image,model,epsilon, label, alpha, num_iter):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        model.eval()\n",
        "        o = model(norm((image + delta)))\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "\n",
        "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "        delta.grad.zero_()\n",
        "\n",
        "\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp4lK_24Tn_2"
      },
      "source": [
        "\n",
        "def rectified_bim(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    \n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(norm(image))\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model(norm((image + delta)))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model(norm((image + delta)))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model(norm((image + delta)))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp, retain_graph=True)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp, retain_graph=True)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "            inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_match] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "            delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp2KiKzAmiFL"
      },
      "source": [
        "def pgd(image,model,epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for i in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            model.eval()\n",
        "            o = model(norm((image + delta)))\n",
        "\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            loss.backward(torch.ones_like(loss))\n",
        "\n",
        "            delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "            delta.grad.zero_()\n",
        "        \n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model(norm((image + delta))),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejNX1gqa1tnD"
      },
      "source": [
        "\n",
        "def rectified_pgd(image, model, epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for r in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            o = model(norm(image))\n",
        "            o = softmax(o)\n",
        "        init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "        enable_dropout(model)\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "            for i in range(50):\n",
        "\n",
        "                enable_dropout(model)\n",
        "                output = model(norm((image + delta)))\n",
        "                output = softmax(output)\n",
        "\n",
        "                dropout_predictions[i] = output\n",
        "\n",
        "            variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "            var = variance.mean(1,True)\n",
        "            var = var.reshape(1,item_count)\n",
        "            var = var.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            o = model(norm((image + delta)))\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            if t == 0:\n",
        "\n",
        "                loss.backward(torch.ones_like(var))\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                var.backward(torch.ones_like(var))\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_unc = torch.where(delta_unc != delta_loss, zeros, delta_unc)\n",
        "                delta.data = (delta + alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            else:\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    o = model(norm((image + delta)))\n",
        "                    o = softmax(o)\n",
        "                inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_notmatch] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp, retain_graph=True)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp, retain_graph=True)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc != delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "                inds_match = np.where(inter_pred.cpu() == init_pred.cpu())[0]\n",
        "\n",
        "                temp = torch.ones_like(var)\n",
        "                temp = temp.cpu().numpy()\n",
        "\n",
        "                temp[0][inds_match] = 0\n",
        "                temp = torch.tensor(temp)\n",
        "                temp = temp.to(device)\n",
        "\n",
        "                var.backward(temp)\n",
        "                delta_unc = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                loss.backward(temp)\n",
        "                delta_loss = delta.grad.detach().sign()\n",
        "                delta.grad.zero_()\n",
        "                delta.grad = None\n",
        "\n",
        "                zeros = torch.zeros_like(delta_loss)\n",
        "                delta_loss = torch.where(delta_unc == delta_loss, zeros, delta_loss)\n",
        "                delta.data = (delta + alpha * delta_loss).clamp(-epsilon, epsilon)\n",
        "\n",
        "    ##########################################################################################\n",
        "\n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model(norm((image + delta))),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXVE8LMATpsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fa4b39-98af-4750-f3f3-1fb81f6e0472"
      },
      "source": [
        "\n",
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(norm(image))\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "\n",
        "    preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
        "\n",
        "    #pert = fgsm(image, model_cnn, eps, label)\n",
        "    \n",
        "    #pert = rectified_fgsm(image, model_cnn, eps)\n",
        "\n",
        "    #pert = bim(image, model_cnn, eps, label, alpha, num_iter)\n",
        "\n",
        "    #pert = rectified_bim(image, model_cnn, eps, num_iter, alpha)\n",
        "\n",
        "    #pert = pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)\n",
        "    \n",
        "    pert = rectified_pgd(image, model_cnn, eps, label, alpha, num_iter, num_restart)\n",
        "\n",
        "    #attack = LinfDeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1),preprocessing=preprocessing)\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(norm(pert))\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "    inds_correct_after_attackk = inds_correct_after_attack.tolist()\n",
        "    inds_wrong_after_attackk = inds_wrong_after_attack.tolist()\n",
        "\n",
        "    count_unsuccessfull_attack += len(inds_correct_after_attackk)\n",
        "    count_successfull_attack += len(inds_wrong_after_attackk)\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "\n",
        "    if i%30==0:\n",
        "      print(\"Success ratio for the attack is : %{:.2f}\".format(\n",
        "    100 * count_successfull_attack / (count_successfull_attack + count_unsuccessfull_attack)))\n",
        "\n",
        "    #if i == 0:\n",
        "        #break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success ratio for the attack is : %65.31\n",
            "Success ratio for the attack is : %65.81\n",
            "Success ratio for the attack is : %65.75\n",
            "Success ratio for the attack is : %66.20\n",
            "Success ratio for the attack is : %66.95\n",
            "Success ratio for the attack is : %67.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEiEdesVTscK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ed39ab-5383-4185-b680-a244bf42cd29"
      },
      "source": [
        "print(\"Number of successful attack is : \", count_successfull_attack)\n",
        "print(\"Number of unsuccessful attack is : \", count_unsuccessfull_attack)\n",
        "\n",
        "print(\"Success ratio for the attack is : %{:.2f}\".format(\n",
        "    100 * count_successfull_attack / (count_successfull_attack + count_unsuccessfull_attack)))\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successful attack is :  5587\n",
            "Number of unsuccessful attack is :  2734\n",
            "Success ratio for the attack is : %67.14\n",
            "2021-09-07 00:50:54\n"
          ]
        }
      ]
    }
  ]
}