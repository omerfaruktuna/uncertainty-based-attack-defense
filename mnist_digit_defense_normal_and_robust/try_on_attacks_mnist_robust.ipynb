{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "try_on_attacks_mnist_robust.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq672y9uNbTb",
        "outputId": "ff7711a6-ba2e-4048-ec0e-523e6ba8e820"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 225 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 256 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 276 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 296 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 307 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 327 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 337 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 348 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 358 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 378 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 389 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 399 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 409 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 419 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 430 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 440 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 450 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 460 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 481 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 491 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 501 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 512 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 532 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 542 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 552 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 563 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 583 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 593 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 604 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 614 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 624 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 634 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 645 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 655 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 665 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 675 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 686 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 696 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 706 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 716 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 727 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 737 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 747 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 757 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 768 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 778 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 788 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 798 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 808 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 819 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 829 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 839 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 849 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 860 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 870 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 880 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 890 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 901 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 911 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 921 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 931 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 942 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 952 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 962 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 972 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 983 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 993 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.4 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.6 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7 MB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Collecting GitPython>=3.0.7\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 905 kB/s \n",
            "\u001b[?25hCollecting eagerpy==0.29.0\n",
            "  Downloading eagerpy-0.29.0-py3-none-any.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Installing collected packages: smmap, gitdb, requests, GitPython, eagerpy, foolbox\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.18 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.26.0 smmap-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2jW6C2Nmea"
      },
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqsac7FMSyD"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models\n",
        "import urllib\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBnc3FnMcdF"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*32, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.2)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = self.drop_layer(F.relu(self.conv1(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHxJYlYNs43"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cegubmYQDgmg",
        "outputId": "cfcd4560-c47e-45b4-9958-6842e21e5421"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXZHB-t63nvi"
      },
      "source": [
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCTWpJeMhmH"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 0.1\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 1.35\n",
        "\n",
        "eps_little = 0.02\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 10\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "\n",
        "test_data = datasets.MNIST(root='data', train=False, download=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwKm-A1gM1ZC",
        "outputId": "1df0c5da-7d76-4438-a38b-38ac1f446fe4"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = Model_Drop()\n",
        "\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn_robust.pt\",map_location=device))\n",
        "\n",
        "model_cnn.eval()\n",
        "model_cnn.to(device)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-09 13:50:07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6C5yBDM5AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307cceb7-a3b1-4a40-cc3f-de966fbf8fec"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(image)\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "\n",
        "    #attack = LinfFastGradientAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = LinfBasicIterativeAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = LinfDeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = L2DeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    attack = L2CarliniWagnerAttack(steps=1000, confidence = 10)\n",
        "    fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    if inds_wrong_after_attack.shape[0] == 0:\n",
        "        continue\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "    pred_pert = pred_pert[inds_wrong_after_attack]\n",
        "\n",
        "    reversed_pert = unc_defense(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    reversed_pert = reversed_pert[inds_correct_after_reverse]\n",
        "    image = image[inds_correct_after_reverse]\n",
        "    label = label[inds_correct_after_reverse]\n",
        "    pert = pert[inds_correct_after_reverse]\n",
        "    pred_pert = pred_pert[inds_correct_after_reverse]\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n",
        "\n",
        "    if i%10 == 0:\n",
        "      print(i)\n",
        "      #break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-KlO9zTNWN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d47cf60-bc57-4b3e-bf2d-8e68e4beba67"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successful reverse operation is :  78\n",
            "Number of unsuccessful reverse operation is :  401\n",
            "2021-09-09 17:17:43\n"
          ]
        }
      ]
    }
  ]
}