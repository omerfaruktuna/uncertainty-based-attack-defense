{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_mnist_adversarial_normal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDiD6L2cNMVe",
        "outputId": "163da06e-ff4b-46d3-aeaa-b014d551e034"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LroJaylUuYdJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=False, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size = 64, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 64, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pljaI0abupYV"
      },
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZCsIh1u2ON"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*32, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.2)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = self.drop_layer(F.relu(self.conv1(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_cnn_robust = Model_Drop()\n",
        "model_cnn_robust = model_cnn_robust.to(device)\n",
        "\n",
        "model_cnn_normal = Model_Drop()\n",
        "model_cnn_normal = model_cnn_normal.to(device)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceM_jADCvKai"
      },
      "source": [
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "\n",
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    model.eval()\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "        \n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ETx4u4kvdZU"
      },
      "source": [
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "\n",
        "    if opt:\n",
        "      model.train()\n",
        "      enable_dropout(model)\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
        "    total_loss, total_err = 0.,0.\n",
        "\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y, **kwargs)\n",
        "\n",
        "        if opt:\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)        \n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoj7rzFYvuQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f654fa-9c40-4e01-9ddf-df963ea9bbe1"
      },
      "source": [
        "#optt = optim.SGD(model_cnn_normal.parameters(), lr=1e-1)\n",
        "optt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "\n",
        "for t in range(10):\n",
        "\n",
        "  test_err, test_loss = 0,0\n",
        "\n",
        "  #train_err, train_loss = epoch(train_loader, model_cnn_normal, optt)\n",
        "  #test_err, test_loss = epoch(train_loader, model_cnn_normal)\n",
        "  train_err, train_loss = epoch_adversarial(train_loader, model_cnn_robust, pgd_linf, optt)\n",
        "  test_err, test_loss = epoch_adversarial(train_loader, model_cnn_robust, pgd_linf)\n",
        "\n",
        "  if t == 4:\n",
        "    for param_group in optt.param_groups:\n",
        "      param_group[\"lr\"] = 1e-2\n",
        "  print(*(\"{:.6f}\".format(i) for i in (train_err, test_err)), sep=\"\\t\")\n",
        "\n",
        "model_cnn_robust.eval()\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")\n",
        "\n",
        "#model_cnn_normal.eval()\n",
        "#torch.save(model_cnn_normal.state_dict(), \"model_cnn_normal.pt\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.310183\t0.072767\n",
            "0.049000\t0.040450\n",
            "0.032517\t0.031933\n",
            "0.026217\t0.039483\n",
            "0.022783\t0.017650\n",
            "0.015000\t0.013683\n",
            "0.014150\t0.013117\n",
            "0.013533\t0.012767\n",
            "0.013067\t0.012417\n",
            "0.012883\t0.012217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Vaif5V9JqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5279c8a7-e996-4cc5-cab8-328fb1b445c7"
      },
      "source": [
        "#model_cnn_normal.eval()\n",
        "#print(epoch(test_loader, model_cnn_normal)[0])\n",
        "\n",
        "model_cnn_robust.eval()\n",
        "print(epoch(test_loader, model_cnn_robust)[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0066\n"
          ]
        }
      ]
    }
  ]
}